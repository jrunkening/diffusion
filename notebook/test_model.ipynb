{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import datasets, transforms\n",
    "from diffusion.noise_scheduler import NoiseScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = Path(\"../data\")\n",
    "test_data = datasets.CelebA(\n",
    "    root=DATA_PATH,\n",
    "    split=\"test\",\n",
    "    transform=transforms.ToTensor(),\n",
    "    download=True\n",
    ")\n",
    "data = test_data[0][0].reshape(1, 3, 218, 178)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, shape, in_c, out_c, activation, mode, kernel_size=3, stride=1, padding=1) -> None:\n",
    "        super().__init__()\n",
    "        self.normalize = nn.LayerNorm((in_c, *shape))\n",
    "        self.Conv = nn.Conv2d if mode == \"down\" else nn.ConvTranspose2d\n",
    "\n",
    "        self.conv0 = self.Conv(in_c, out_c, kernel_size, stride, padding)\n",
    "        self.conv1 = self.Conv(out_c, out_c, kernel_size, stride, padding)\n",
    "        self.conv2 = self.Conv(out_c, out_c, kernel_size, stride, padding)\n",
    "        self.activation = activation\n",
    "\n",
    "        self.shortcut = self.Conv(in_c, out_c, kernel_size, stride, padding)\n",
    "\n",
    "    def forward(self, xs):\n",
    "        xs = self.normalize(xs)\n",
    "\n",
    "        out = self.conv0(xs)\n",
    "        out = self.activation(out)\n",
    "        out = self.conv1(out)\n",
    "        out = self.activation(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.activation(out)\n",
    "\n",
    "        out += self.shortcut(xs)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xs = torch.Size([1, 3, 218, 178])\n",
      "h0 = torch.Size([1, 16, 109, 89])\n",
      "h1 = torch.Size([1, 32, 55, 45])\n",
      "h2 = torch.Size([1, 64, 28, 23])\n",
      "h3 = torch.Size([1, 128, 14, 12])\n",
      "ht1 = torch.Size([1, 64, 28, 23])\n",
      "ht1 = torch.Size([1, 32, 55, 45])\n",
      "ht1 = torch.Size([1, 16, 109, 89])\n",
      "ht0 = torch.Size([1, 3, 218, 178])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.0822,  0.0922,  0.0397,  ...,  0.0521,  0.0818,  0.0111],\n",
       "          [ 0.0144,  0.1985, -0.1695,  ..., -0.0273,  0.0137, -0.0807],\n",
       "          [ 0.0523,  0.1237,  0.0165,  ..., -0.0982,  0.1035,  0.0761],\n",
       "          ...,\n",
       "          [-0.0008, -0.0903,  0.0863,  ...,  0.0272, -0.0009, -0.0244],\n",
       "          [ 0.0195,  0.1126, -0.0852,  ..., -0.0110, -0.2137, -0.0883],\n",
       "          [ 0.0169, -0.0595, -0.0274,  ..., -0.0188, -0.0211,  0.0199]],\n",
       "\n",
       "         [[ 0.0749,  0.0782,  0.0335,  ...,  0.0597,  0.2029,  0.0909],\n",
       "          [ 0.0694,  0.2537,  0.4160,  ...,  0.1461,  0.0308,  0.0354],\n",
       "          [ 0.0579,  0.0284, -0.1273,  ..., -0.0588, -0.0159,  0.0448],\n",
       "          ...,\n",
       "          [ 0.0301,  0.0847, -0.0307,  ..., -0.0933,  0.3191,  0.0439],\n",
       "          [-0.0017,  0.1677,  0.0938,  ..., -0.0585,  0.1483,  0.0453],\n",
       "          [ 0.0287,  0.0421, -0.0141,  ...,  0.0241,  0.1371, -0.0094]],\n",
       "\n",
       "         [[ 0.1474,  0.0933,  0.1095,  ..., -0.0047,  0.0128,  0.0774],\n",
       "          [-0.0521, -0.0583, -0.0131,  ...,  0.0963,  0.1123,  0.0515],\n",
       "          [-0.0778,  0.1968,  0.1271,  ...,  0.0436, -0.0891,  0.0630],\n",
       "          ...,\n",
       "          [ 0.0219, -0.1389,  0.1829,  ...,  0.0273, -0.0136,  0.1411],\n",
       "          [ 0.1131,  0.0924,  0.1511,  ...,  0.0844,  0.0410,  0.0842],\n",
       "          [ 0.0236,  0.0752,  0.0342,  ...,  0.0202,  0.1658,  0.1148]]]],\n",
       "       grad_fn=<ConvolutionBackward0>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.register_buffer(\"embedding_w\", torch.randn(256//2))\n",
    "        self.noise_scheduler = NoiseScheduler(0, 0.02, 1000)\n",
    "\n",
    "        self.channels = [3, 16, 32, 64, 128]\n",
    "        self.activation = nn.SiLU()\n",
    "\n",
    "        self.l0 = nn.Linear(256, self.channels[0])\n",
    "        self.b0 = nn.Sequential(\n",
    "            ResBlock((218, 178), self.channels[0], self.channels[1], self.activation, \"down\"),\n",
    "            ResBlock((218, 178), self.channels[1], self.channels[1], self.activation, \"down\"),\n",
    "            ResBlock((218, 178), self.channels[1], self.channels[1], self.activation, \"down\"),\n",
    "        )\n",
    "        self.down0 = nn.Conv2d(self.channels[1], self.channels[1], kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        self.l1 = nn.Linear(256, self.channels[1])\n",
    "        self.b1 = nn.Sequential(\n",
    "            ResBlock((109, 89), self.channels[1], self.channels[2], self.activation, \"down\"),\n",
    "            ResBlock((109, 89), self.channels[2], self.channels[2], self.activation, \"down\"),\n",
    "            ResBlock((109, 89), self.channels[2], self.channels[2], self.activation, \"down\"),\n",
    "        )\n",
    "        self.down1 = nn.Conv2d(self.channels[2], self.channels[2], kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        self.l2 = nn.Linear(256, self.channels[2])\n",
    "        self.b2 = nn.Sequential(\n",
    "            ResBlock((55, 45), self.channels[2], self.channels[3], self.activation, \"down\"),\n",
    "            ResBlock((55, 45), self.channels[3], self.channels[3], self.activation, \"down\"),\n",
    "            ResBlock((55, 45), self.channels[3], self.channels[3], self.activation, \"down\"),\n",
    "        )\n",
    "        self.down2 = nn.Conv2d(self.channels[3], self.channels[3], kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        self.l3 = nn.Linear(256, self.channels[3])\n",
    "        self.b3 = nn.Sequential(\n",
    "            ResBlock((28, 23), self.channels[3], self.channels[4], self.activation, \"down\"),\n",
    "            ResBlock((28, 23), self.channels[4], self.channels[4], self.activation, \"down\"),\n",
    "            ResBlock((28, 23), self.channels[4], self.channels[4], self.activation, \"down\"),\n",
    "        )\n",
    "        self.down3 = nn.Conv2d(self.channels[4], self.channels[4], kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "\n",
    "        self.lt3 = nn.Linear(256, self.channels[4])\n",
    "        self.bt3 = nn.Sequential(\n",
    "            ResBlock((14, 12), self.channels[4], self.channels[3], self.activation, \"up\"),\n",
    "            ResBlock((14, 12), self.channels[3], self.channels[3], self.activation, \"up\"),\n",
    "            ResBlock((14, 12), self.channels[3], self.channels[3], self.activation, \"up\"),\n",
    "        )\n",
    "        self.up3 = nn.ConvTranspose2d(self.channels[3], self.channels[3], kernel_size=(4, 3), stride=2, padding=1)\n",
    "\n",
    "        self.lt2 = nn.Linear(256, self.channels[3])\n",
    "        self.bt2 = nn.Sequential(\n",
    "            ResBlock((28, 23), 2*self.channels[3], self.channels[2], self.activation, \"up\"),\n",
    "            ResBlock((28, 23), self.channels[2], self.channels[2], self.activation, \"up\"),\n",
    "            ResBlock((28, 23), self.channels[2], self.channels[2], self.activation, \"up\"),\n",
    "        )\n",
    "        self.up2 = nn.ConvTranspose2d(self.channels[2], self.channels[2], kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        self.lt1 = nn.Linear(256, self.channels[2])\n",
    "        self.bt1 = nn.Sequential(\n",
    "            ResBlock((55, 45), 2*self.channels[2], self.channels[1], self.activation, \"up\"),\n",
    "            ResBlock((55, 45), self.channels[1], self.channels[1], self.activation, \"up\"),\n",
    "            ResBlock((55, 45), self.channels[1], self.channels[1], self.activation, \"up\"),\n",
    "        )\n",
    "        self.up1 = nn.ConvTranspose2d(self.channels[1], self.channels[1], kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        self.lt0 = nn.Linear(256, self.channels[1])\n",
    "        self.bt0 = nn.Sequential(\n",
    "            ResBlock((109, 89), 2*self.channels[1], self.channels[0], self.activation, \"up\"),\n",
    "            ResBlock((109, 89), self.channels[0], self.channels[0], self.activation, \"up\"),\n",
    "            ResBlock((109, 89), self.channels[0], self.channels[0], self.activation, \"up\"),\n",
    "        )\n",
    "        self.up0 = nn.ConvTranspose2d(self.channels[0], self.channels[0], kernel_size=4, stride=2, padding=1)\n",
    "\n",
    "    def preprocess(self, xs):\n",
    "        ts = torch.randint(1, self.noise_scheduler.steps, (len(xs),))\n",
    "        xs, ys = self.noise_scheduler.forward_process(xs, ts)\n",
    "\n",
    "        return xs, ts, ys\n",
    "\n",
    "    def embed(self, ts, linear):\n",
    "        embedding = 30 * torch.outer(ts, self.embedding_w)\n",
    "        embedding = torch.cat([torch.sin(embedding), torch.cos(embedding)], dim=1)\n",
    "        embedding = self.activation(linear(embedding))\n",
    "        embedding = embedding.reshape(*embedding.shape, 1, 1)\n",
    "\n",
    "        return embedding\n",
    "\n",
    "    def forward(self, xs, ts):\n",
    "        print(f\"xs = {xs.shape}\")\n",
    "\n",
    "        h0 = self.down0(self.b0(xs + self.embed(ts, self.l0)))\n",
    "        print(f\"h0 = {h0.shape}\")\n",
    "        h1 = self.down1(self.b1(h0 + self.embed(ts, self.l1)))\n",
    "        print(f\"h1 = {h1.shape}\")\n",
    "        h2 = self.down2(self.b2(h1 + self.embed(ts, self.l2)))\n",
    "        print(f\"h2 = {h2.shape}\")\n",
    "        h3 = self.down3(self.b3(h2 + self.embed(ts, self.l3)))\n",
    "        print(f\"h3 = {h3.shape}\")\n",
    "\n",
    "        h = self.up3(self.bt3(h3 + self.embed(ts, self.lt3)))\n",
    "        print(f\"ht1 = {h.shape}\")\n",
    "        h = self.up2(self.bt2(torch.cat((h + self.embed(ts, self.lt2), h2), dim=1)))\n",
    "        print(f\"ht1 = {h.shape}\")\n",
    "        h = self.up1(self.bt1(torch.cat((h + self.embed(ts, self.lt1), h1), dim=1)))\n",
    "        print(f\"ht1 = {h.shape}\")\n",
    "        h = self.up0(self.bt0(torch.cat((h + self.embed(ts, self.lt0), h0), dim=1)))\n",
    "        print(f\"ht0 = {h.shape}\")\n",
    "\n",
    "        return h\n",
    "\n",
    "\n",
    "model = Model()\n",
    "xs, ts, _ = model.preprocess(data)\n",
    "model(xs, ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffusion--2hlmT2A-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
